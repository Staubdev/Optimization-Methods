{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sympy import ordered, Matrix, hessian, lambdify\n",
    "from sympy.abc import x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "# use sympy to return a lambda function for the gradient and hessian of an equation\n",
    "def compute_gradient_hessian(eq, *args):\n",
    "    f = eq(*args)\n",
    "    vars = list(ordered(f.free_symbols))\n",
    "\n",
    "    gradient = lambda func, vars : Matrix([func]).jacobian(vars)\n",
    "\n",
    "    grad_lambda = lambda x : lambdify(vars, gradient(f, vars))(*x).flatten()\n",
    "    hess_lambda = lambda x : lambdify(vars, hessian(f, vars))(*x)\n",
    "\n",
    "    return grad_lambda, hess_lambda\n",
    "\n",
    "def quadratic_model(f_k, grad_k, hess_k):\n",
    "    return lambda p : f_k + p.dot(grad_k) + 0.5 * p.dot(hess_k).dot(p)\n",
    "\n",
    "# return the positive root of Tau using the quadratic formula\n",
    "def find_tau(z_j, d_j, radius):\n",
    "    a = z_j.dot(z_j)\n",
    "    b = z_j.dot(d_j)\n",
    "    c = d_j.dot(d_j)\n",
    "    return (np.sqrt(c*(radius**2 - a) + b**2) - b) / c\n",
    "\n",
    "# page 171 in Nocedal\n",
    "# find Tau directly by using the quadratic formula\n",
    "def steihaug(radius, grad_k, hess_k, eps=1e-8):\n",
    "    z_j = np.zeros(grad_k.size)\n",
    "    r_j = np.copy(grad_k)\n",
    "    d_j = -np.copy(grad_k)\n",
    "\n",
    "    if np.linalg.norm(grad_k) < eps:\n",
    "        return z_j\n",
    "\n",
    "    while True:\n",
    "        dBd = d_j.dot(hess_k).dot(d_j)\n",
    "\n",
    "        # Negative curvature condition\n",
    "        if dBd <= 0:\n",
    "            # return the intersection of the current direction with the trust-region boundary\n",
    "            return z_j + find_tau(z_j, d_j, radius) * d_j\n",
    "\n",
    "        alpha_j = (r_j.dot(r_j)) / dBd\n",
    "        z_old = np.copy(z_j)\n",
    "        z_j += alpha_j * d_j\n",
    "\n",
    "        # Trust region condition\n",
    "        if np.linalg.norm(z_j) >= radius:\n",
    "            # return the intersection of the current direction with the trust-region boundary\n",
    "            return z_j + find_tau(z_j, d_j, radius) * d_j\n",
    "\n",
    "        r_old = np.copy(r_j)\n",
    "        r_j += alpha_j * hess_k.dot(d_j)\n",
    "\n",
    "        # Stopping condition\n",
    "        if np.linalg.norm(r_j) < eps:\n",
    "            return z_j\n",
    "\n",
    "        beta_j = (r_j.dot(r_j)) / (r_old.dot(r_old))\n",
    "        d_j = beta_j * d_j - r_j\n",
    "\n",
    "\n",
    "\n",
    "# n must be between 0 and 0.25\n",
    "# from Nocedal page 69\n",
    "def trust_region(f, f_grad, f_hess, x_0, tol=1e-15, model=quadratic_model, radius_0=1.0, radius_max=300.0, n=1e-3):\n",
    "    k = 0\n",
    "    x_k = x_0\n",
    "    radius = radius_0\n",
    "\n",
    "    # evaluate function, gradient, hessian, and model function at x_k\n",
    "    f_k = f(x_k)\n",
    "    grad_k = f_grad(x_k)\n",
    "    hess_k = f_hess(x_k)\n",
    "    model_k = model(f_k, grad_k, hess_k)\n",
    "\n",
    "    while np.linalg.norm(f_grad(x_k)) > tol:\n",
    "        # solve subproblem using Steihaug's Method\n",
    "        p_k = steihaug(radius, grad_k, hess_k)\n",
    "\n",
    "        # evaluate agreement between model function and actual function\n",
    "        rho_k = (f(x_k) - f(x_k + p_k)) / (f(x_k) - model_k(p_k))\n",
    "\n",
    "        if rho_k < 0.25:\n",
    "            # poor approximation so shrink the trust-radius\n",
    "            radius = 0.25 * radius\n",
    "        elif rho_k > 0.75 and np.abs(np.linalg.norm(p_k) - radius) < tol:\n",
    "            # good approximation and a full-step (within tolerance) was taken, expand trust_radius\n",
    "            radius = min(2 * radius, radius_max)\n",
    "        # otherwise leave the radius unchanged\n",
    "\n",
    "        # if approximation was good, update x to the new step. Otherwise leave x unchanged\n",
    "        if rho_k > n:\n",
    "            x_k = x_k + p_k\n",
    "\n",
    "            # update function evaluation, gradient, hessian, and model function at x_k+1\n",
    "            f_k = f(x_k)\n",
    "            grad_k = f_grad(x_k)\n",
    "            hess_k = f_hess(x_k)\n",
    "            model_k = model(f_k, grad_k, hess_k)\n",
    "\n",
    "        k += 1\n",
    "\n",
    "        if np.linalg.norm(p_k) < tol:\n",
    "            break\n",
    "\n",
    "    return [x_k, k]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2m/pnw5mkds7jlbndvtgss60thc0000gn/T/ipykernel_98946/4201230372.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  rho_k = (f(x_k) - f(x_k + p_k)) / (f(x_k) - model_k(p_k))\n"
     ]
    },
    {
     "data": {
      "text/plain": "[array([1., 1.]), 45]"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rosenbrock function\n",
    "a = 1\n",
    "b = 100\n",
    "rosenbrock = lambda x : (a-x[0])**2 + b*(x[1]-x[0]**2)**2\n",
    "\n",
    "rosen_grad, rosen_hess = compute_gradient_hessian(rosenbrock, [x, y])\n",
    "\n",
    "trust_region(rosenbrock, rosen_grad, rosen_hess, [10, 20])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "##Subroutines\n",
    "def vlist(x):##Converts vectors to lists\n",
    "    return x.flatten().tolist()[0]\n",
    "\n",
    "##Main Function\n",
    "def linetrace(F,J,alpha,P,x0,tol):##Modulator Form Solves x_n+1=x_n+alpha*p(x_n)\n",
    "    x=x0\n",
    "    p=P(F,J)##Produces a function p(x)\n",
    "    p0=p(x)\n",
    "    log=[[],[]]\n",
    "    ##sol=np.matrix([0.7937005259840997, 0.7937005259840997]).T #F1 solution\n",
    "    sol=np.matrix([1.,1.]) #F2 Solution\n",
    "    for n in range(20000):\n",
    "        v=np.matrix(x).T\n",
    "        a=alpha(F,J,p0,x,v)##Finds the alpha\n",
    "        v+=a*p0\n",
    "        x=vlist(v.T)\n",
    "        px=p(x)\n",
    "        er=np.linalg.norm(px-p0)\n",
    "        log[0].append(n)\n",
    "        log[1].append(np.linalg.norm(sol-v))##Real Error\n",
    "        #log[1].append(er)##Assumed error\n",
    "        if er<10.**(-tol):\n",
    "            return x, n, log, 0\n",
    "        p0=px\n",
    "    return x, 'MAX',log, 1\n",
    "\n",
    "##P(x) Functions\n",
    "\n",
    "def gradg(F,J):##Produces -grad b for p(x)\n",
    "    def grad(x):\n",
    "        return -1.*J(x).T*F(x)\n",
    "    return grad\n",
    "\n",
    "def Newton(F,J):\n",
    "    def newton(x):\n",
    "        return -1*J(x)**-1*F(x)\n",
    "    return newton\n",
    "\n",
    "\n",
    "##alpha functions\n",
    "def hquad(F,J,p,x,v):##Creates a 1D quadratic intelopalation for g(x_n+alpha*p(x_n))in terms of alpha.\n",
    "    def g(x):##Calculates sum fi^2 might need extension in future\n",
    "        f=F(x)\n",
    "        g=f.T*f\n",
    "        return vlist(g)[0]\n",
    "    h0=g(x)\n",
    "    b=1.\n",
    "    for i in range(1075):##Number goes to machine minimum\n",
    "        h4=g((v+b*p).T.flatten().tolist()[0])\n",
    "        if h0>h4:##Checks if the interval is too large in an attempt to find a basin of convergence.\n",
    "            b1=b*(.5*np.cos(math.pi/6.)+.5) ##The intelopalation runs off of Chebyshev points for accuracy.\n",
    "            b2=b*(.5*np.cos(3*math.pi/6.)+.5)\n",
    "            b3=b*(.5*np.cos(5*math.pi/6.)+.5)\n",
    "            h1=g(vlist((v+b1*p).T))\n",
    "            h2=g(vlist((v+b2*p).T))\n",
    "            h3=g(vlist((v+b3*p).T))\n",
    "            a1=(h2-h1)/(b2-b1)\n",
    "            a2=(h2-a1*(b2-b1))/(b3-b1)/(b3-b2)\n",
    "            bm=(a2*(b1+b2)-a1)/(2.*a2)\n",
    "            hm=g(vlist((v+bm*p).T))\n",
    "            if hm<h4:##The 0 of the derivative should usually be a local minima but just in\n",
    "                return bm\n",
    "            else:\n",
    "                return b\n",
    "        b*=.5\n",
    "    return b ##If no basin is found it is likely due to machine error, and the approximation cannot continue further.\n",
    "\n",
    "##Identical to hquad but doesn't use Chebyshev nodes\n",
    "def hquad2(F,J,p,x,v):##Creates a 1D quadratic intelopalation for g(x_n+alpha*p(x_n))in terms of alpha.\n",
    "    def g(x):##Calculates sum fi^2 might need extension in future\n",
    "        f=F(x)\n",
    "        g=f.T*f\n",
    "        return vlist(g)[0]\n",
    "    h0=g(x)\n",
    "    b=1.\n",
    "    for i in range(1075):##Number goes to machine minimum\n",
    "        h4=g((v+b*p).T.flatten().tolist()[0])\n",
    "        if h0>h4:##Checks if the interval is too large in an attempt to find a basin of convergence.\n",
    "            b1=0##Uses standard nodes\n",
    "            b2=.5*b\n",
    "            b3=b\n",
    "            h1=h0\n",
    "            h2=g(vlist((v+b2*p).T))\n",
    "            h3=h4\n",
    "            a1=(h2-h1)/(b2-b1)\n",
    "            a2=(h2-a1*(b2-b1))/(b3-b1)/(b3-b2)\n",
    "            bm=(a2*(b1+b2)-a1)/(2.*a2)\n",
    "            hm=g(vlist((v+bm*p).T))\n",
    "            if hm<h4:##The 0 of the derivative should usually be a local minima but just in\n",
    "                return bm\n",
    "            else:\n",
    "                return b\n",
    "        b*=.5\n",
    "    return b ##If no basin is found it is likely due to machine error, and the approximation cannot continue further.\n",
    "\n",
    "def cons(F,J,p,x,v):##constant alpha\n",
    "    return 1\n",
    "\n",
    "def Wolfe(F,J,p,x,v):\n",
    "    def g(x):##Calculates sum fi^2 might need extension in future\n",
    "        f=F(x)\n",
    "        g=f.T*f\n",
    "        return vlist(g)[0]\n",
    "    h0=g(x)\n",
    "    Dg=gradg(F,J)\n",
    "    dg=Dg(x)\n",
    "    c1=10**-4\n",
    "    c2=.1\n",
    "    a=1.\n",
    "    for i in range(1075):##Number goes to machine minimum\n",
    "        h=g((v+a*p).T.flatten().tolist()[0])\n",
    "        dgx=Dg((v+a*p).T.flatten().tolist()[0])\n",
    "        Arm=vlist(dg.T*p)[0]\n",
    "        Cur=vlist(dgx.T*p)[0]\n",
    "        if (h<=h0+c1*a*Arm and Cur>=c2*Arm):#Wolfe conditions\n",
    "            return a\n",
    "        a*=.5\n",
    "    return a"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}